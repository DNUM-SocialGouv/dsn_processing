# Structure des scripts d'int√©gration

## Organisation

### Natures des tables d'int√©gration

La base Champollion comporte des tables permanentes qu'elles soient de natures statiques (tables contextuelles) ou dynamiques (tables mises √† jour chaque mois). Pour plus de d√©tails, voir le [cahier technique](../../database/guide_technique_bases_de_donnees.md) de la base Champollion. En compl√©ment de ces tables, des tables temporaires sont n√©cessaires afin d'int√©grer de nouvelles donn√©es. On distingue quatre types de tables temporaires :

- les **tables raw** permettent l'import en base de donn√©es brutes √† partir de fichiers csv ;
- les **tables source** sont cr√©√©es √† partir des tables *raw* et permettent le formattage des donn√©es brutes ;
- les **tables link** sont n√©cessaires afin d'enregistrer le mapping entre les id dans la base brute des lignes brutes et l'id en base Champollion de ligne mise √† jour ou cr√©√©e en cons√©quence ;
- les **tables map** permettent le recensement des lignes √† fusionner lors des op√©rations de prise en compte des changements de clefs identifiantes.

Dans la base de donn√©es, les tables *raw* font l'objet d'un sch√©ma **raw** et les tables *source*, *link* et *map* sont regroup√©es dans un sch√©ma **source**.

Ainsi, l'import de donn√©es suit le sch√©ma suivant : 

![etlm](../../images/etlm.png)

[Lien √©ditable](https://excalidraw.com/#json=6bUVDQbLfSIEkWDwk3_5p,bwHisIrHAzz_nVuuUvKS9Q)

### Tables de log

Les op√©rations effectu√©es sur la base sont loggu√©es √† trois niveaux :

- dans la table `log.integrations_logs`, chaque int√©gration fait l'objet de deux lignes (une `BEGIN` et une `END`) enregistrant l'heure de d√©but et de fin de l'int√©gration ainsi que le mois de d√©claration concern√© ;
- dans la table `log.scripts_logs`, chaque ex√©cution de script SQL est recens√©e dans deux lignes (une `BEGIN` et une `END`) enregistrant l'heure et le nombre de lignes de la table principalement impact√©e au d√©but et √† la fin de l'ex√©cution du script ; 
- dans la table `log.processes_logs`, sur chaque table, chaque proc√©dure (fonctions `INSERT`, `UPDATE`, `DELETE`, `TRUNCATE`) est r√©pertori√©e par deux lignes (une `BEGIN` et une `END`) contenant l'heure et le nombre de lignes de la table au d√©but et √† la fin de la proc√©dure.

La correspondance entre chaque script SQL et sa table principale est issue de la table statique `sys.metadata_scripts`, elle-m√™me aliment√©e √† partir du fichier [`dsn_processing/resources/metadata_scripts.csv`](https://gitlab.intranet.social.gouv.fr/champollion/dsn_processing/blob/dev/resources/metadata_scripts.csv).

### Classification des scripts

#### Axes de classification

Les scripts SQL composant l'ETLM (Extract-Transform-Load-Modify) de la base Champollion peuvent √™tre classifi√©s selon trois dimensions :
-	la famille (aussi appel√©e dag) qui correspond √† la proc√©dure dans lequel il s'inscrit ;
-	le type qui correspond √† l‚Äôop√©ration effectu√©e ;
-	et la nature qui correspond √† la t√¢che effectu√©e.

On distingue trois familles principales (dags) de scripts : 
-	les **scripts `init_database`** relatifs √† l'initialisation de la base ;
-   les **scripts `update_database`** relatifs √† la mise √† jour p√©riodique (annuelle ou sur demande) des informations statiques de la base ;
-	les **scripts `monthly_integration`** qui encodent toutes les op√©rations n√©cessaires pour importer mensuellement des donn√©es.

Chaque famille de script fait l'objet d'un dossier sp√©cifique dans `dsn_processing/core/sql/`.

De plus, il existe deux types de scripts :
-	les **processing (P) scripts** : ils encodent une action effectu√©e sur la base sans import de donn√©es.
-	les **importing (I) scripts** : ils encodent un import de donn√©es dans la base et doivent donc √™tre appel√©s avec un csv.

Pour finir, la plupart des scripts peuvent √™tre classifi√©s selon la nomenclature Extract-Transform-Load-Modify. On distingue :
-   les **create (C) scripts** : ils cr√©√©ent les sch√©mas, tables, fonctions de la base ;
-	les **extract (E) scripts** : ils importent les donn√©es brutes dans les tables *raw* ;
-	les **transform (T) scripts** : ils traitent les donn√©es brutes des tables *raw* et les importent dans les tables *source* ;
-	les **load (L) scripts** : ils importent les donn√©es des tables *source* vers les tables permanentes de la base ;
-	les **modify (M) scripts** : ils modifient les donn√©es des tables permanentes de la base.

#### Liste

|  Dag  |  Type |  Nature |  Nom du script  |  Rang d'ex√©cution au sein de sa famille |  Fonction  |
|---|---|---|---|---|---|
|  `init_database`  | P  | C | `create_permanent_tables` | 10 | Cr√©ation de l'ensemble des sch√©mas de la base et des tables permanentes. |
|  `init_database`  | P | C | `create_integration_tables` | 20 | Cr√©ation des tables n√©cessaire pour l'int√©gration (raw, source, link, map). |
|  `init_database`  | P | C | `create_trigger_logs` | 30 | Cr√©ation des trigger functions de logging. |
|  `init_database`  | P | C | `create_dag_status_functions` | 40 | Cr√©ation des fonctions internes pour gestion du statut de la base. |
|  `update_database`  | P | EL | `extract_and_load_metadata` | 10 | Peuplement de la table `sys.metadata_scripts` qui recense les correspondances entre scripts, tables et dags. |
|  `update_database`  | I | EL | `update_naf` | 20 | Insertion des donn√©es manquantes dans la table statique qui recense les codes NAF. |
|  `update_database`  | I | EL | `update_conventions_collectives` | 30 | Insertion des donn√©es manquantes dans la table statique qui recense les codes de convention collective.  |
|  `update_database`  | I | EL | `update_categories_juridiques_insee` | 40 | Insertion des donn√©es manquantes dans la table statique qui recense les codes de cat√©gories juridiques de l‚ÄôINSEE. |
|  `update_database`  | I | EL | `update_motifs_recours`  | 50 | Insertion des donn√©es manquantes dans la table statique qui recense les codes relatifs aux motifs de recours.  |
|  `update_database`  | I | EL | `update_natures_contrats`  | 60 | Insertion des donn√©es manquantes dans la table statique qui recense les codes relatifs aux natures de contrat. |
|  `update_database`  | P | L | `update_calendar` | 70 | Insertion des donn√©es calendaires manquantes dans la table calendrier (via une fonction Postgres). |
|  `update_database`  | I | EL | `update_holidays` | 80 | Mise √† jour du champ `public_holiday` de la table calendrier. |
|  `update_database`  | I | EL | `update_zonage` | 90 | Mise √† jour de la table statique qui recense les appariemments (SIRET, unit√© de contr√¥le). |
|  `monthly_integration` | P | L | `integration_log_begin` | 10 | D√©claration du d√©but de l'int√©gration dans la table de logs des int√©grations. |
|  `monthly_integration` | P | M | `remove_ctt`  | 20 | Suppression de toutes les lignes, cr√©√©es lors d‚Äôun pr√©c√©dent allocate_ctt, qui correspondent aux contrats d‚Äôint√©rim redistribu√©s des entreprises de travail temporaires (ETT) vers les entreprises utilisatrices (ETU).  |
|  `monthly_integration` | P | M | `remove_stt`  | 30 | Suppression de toutes les lignes, cr√©√©es lors d‚Äôun pr√©c√©dent allocate_stt, qui correspondent aux salari√©s int√©rimaires redistribu√©s des ETT vers les ETU. |
|  `monthly_integration` | P | M | `reindex_tables` | 40 | R√©-indexation des tables salari√©s et contrats. |
|  `monthly_integration` | P | M | `set_dernier_mois_de_declaration_integre` | 50 | Renseignement du mois de d√©claration qui est int√©gr√© dans la table public.chargement_donnees. |
|  `monthly_integration` | I | E | `extract_etablissements` | 60 | Insertion des donn√©es brutes dans la table raw. |
|  `monthly_integration` | P | T | `transform_entreprises` | 70 | Peuplement de la table source. |
|  `monthly_integration` | P | L | `load_entreprises`  | 80 | Import des donn√©es mensuelles de la table source dans la table permanente.  |
|  `monthly_integration` | P | T | `transform_etablissements`  | 90 | Peuplement de la table source. |
|  `monthly_integration` | P | L | `load_etablissements` | 100 | Import des donn√©es mensuelles de la table source dans la table permanente.  |
|  `monthly_integration` | P | M | `modify_ouverture_etablissements` | 110 | Inf√©rence du statut ouvert / ferm√© d'un √©tablissement sur l'anciennet√© de sa derni√®re d√©claration. |
|  `monthly_integration` | I | E | `extract_salaries` | 120 | Insertion des donn√©es brutes dans la table raw. |
|  `monthly_integration` | P | T | `transform_salaries`  | 130 | Peuplement de la table source. |
|  `monthly_integration` | P | L | `load_salaries` | 140 | Import des donn√©es mensuelles de la table source dans la table permanente.  |
|  `monthly_integration` | I | E | `extract_contrats` | 150 | Insertion des donn√©es brutes dans la table raw. |
|  `monthly_integration` | P | L | `load_postes` | 160 | Import des nouveaux libell√©s de poste. |
|  `monthly_integration` | P | T | `transform_contrats`  | 170 | Peuplement de la table source. |
|  `monthly_integration` | P | L | `load_contrats` | 180 | Import des donn√©es mensuelles de la table source dans la table permanente.  |
|  `monthly_integration` | I | E | `extract_changements_salaries` | 190 | Insertion des donn√©es brutes dans la table raw. |
|  `monthly_integration` | P | T | `transform_changements_salaries` | 200 | Peuplement de la table source. |
|  `monthly_integration` | P | M | `modify_changements_salaries` | 210 | Modification des donn√©es des tables salari√©s et contrats au regard des changements relatifs aux salari√©s recens√©s. |
|  `monthly_integration` | I | E | `extract_changements_contrats` | 220 | Insertion des donn√©es brutes dans la table raw. |
|  `monthly_integration` | P | T | `transform_changements_contrats` | 230 | Peuplement de la table source. |
|  `monthly_integration` | P | M | `modify_changements_contrats` | 240 | Modification des donn√©es de la table contrats au regard des changements relatifs aux contrats recens√©s. |
|  `monthly_integration` | I | E | `extract_fins_contrats` | 250 | Insertion des donn√©es brutes dans la table raw. |
|  `monthly_integration` | P | T | `transform_fins_contrats` | 260 | Peuplement de la table source. |
|  `monthly_integration` | P | M | `modify_fins_contrats` | 270 |  Modification des valeurs de date de fin dans la table contrats. |
|  `monthly_integration` | P | M | `modify_debuts_contrats`  | 280 |  Modification des valeurs de date de d√©but dans la table contrats. |
|  `monthly_integration` | I | E | `extract_versements` | 290 | Insertion des donn√©es brutes dans la table raw. |
|  `monthly_integration` | I | E | `extract_remunerations` | 300 | Insertion des donn√©es brutes dans la table raw. |
|  `monthly_integration` | I | E | `extract_activites` | 310 | Insertion des donn√©es brutes dans la table raw. |
|  `monthly_integration` | P | T | `transform_activites` | 320 | Peuplement de la table source. |
|  `monthly_integration` | P | L | `load_activites` | 330 | Import des donn√©es mensuelles de la table source dans la table permanente.  |
|  `monthly_integration` | P | M | `remove_old_data` | 340 | Suppression des donn√©es ayant d√©pass√©e la dur√©e maximale de conservation. |
|  `monthly_integration` | P | M | `allocate_stt`  | 350 | Redistribution des salari√©s de travail temporaire des ETT vers les ETU.  |
|  `monthly_integration` | P | M | `allocate_ctt`  | 360 | Redistribution des contrats de travail temporaire des ETT vers les ETU.  |
|  `monthly_integration` | P | | `monthly_sanity_checks` | 370 | V√©rification de tests de coh√©rence sur la base. |
|  `monthly_integration` | P | | `clean_database` | 380 | Suppression des donn√©es des tables des sch√©mas `raw` et `source`. |
|  `monthly_integration` | P | L | `integration_log_end` | 390 | D√©claration de la fin de l'int√©gration dans la table de logs des int√©grations. |

## G√©n√©ration

### Fichier python de g√©n√©ration des scripts SQL

Les scripts SQL sont g√©n√©r√©s via Python car cela permet l'utilisation de fonctions g√©n√©riques. 

**D√®s lors, les scripts SQL ne doivent √™tre g√©n√©r√©s et modifi√©s que via le fichier `dsn_processing/core/sql/generate_sql.py`.**

#### Utilisation du fichier de g√©n√©ration

Le [fichier `dsn_processing/core/sql/generate_sql.py`](https://gitlab.intranet.social.gouv.fr/champollion/dsn_processing/blob/dev/core/sql/generate_sql.py) s'utilise de la fa√ßon suivante.

```bash
usage: generate_sql.py [-h] [-f FILE] [-d DAG] [-v]
Script to generate a SQL task script.
options:
  -h, --help            show this help message and exit
  -f FILE, --file FILE  SQL file name to generate (without extension), generate all files if None.
  -d DAG, --dag DAG     Dag ID to store the SQL script, if not specified set the default value for each task.
  -v, --verbose         print logs
```

Si on veut re-g√©n√©rer l'ensemble des scripts, on ex√©cutera : 

```bash
python core/sql/generate_sql.py
```

#### Modification et ajout de script

Au sein du fichier `dsn_processing/core/sql/generate_sql.py`, le code qui permet l'√©criture d'un script en particulier est sous la forme :

```python
if generate_all or args.file == <script_name>:
    query = ...
    write_sql_file(<default_dag>, <script_name>, query, to_log=<True/False>)
```

Le param√®tre `to_log` de la fonction `write_sql_file` permet, s'il est renseign√© √† `True`, d'ajouter les appels aux fonctions de log au d√©but et √† la fin du script.

Les ... font r√©f√©rence soit √† une cha√Æne de caract√®re encodant une requ√™te SQL soit √† une fonction Python qui renvoie une cha√Æne de caract√®re encodant une requ√™te SQL. Lorsqu'il s'agit d'une fonction, sauf exception, cette derni√®re doit √™tre stock√©e dans le fichier `dsn_processing/core/sql/utils.py`. Voir les deux exemples ci-dessous.

*G√©n√©ration d'un script via une cha√Æne de caract√®re.*

```python
if generate_all or args.file == "create_test":
    query = """CREATE TABLE test (id INTEGER PRIMARY KEY, field TEXT);"""
    write_sql_file("create_dag", "create_test", query, to_log=True)
```

*G√©n√©ration d'un script par appel d'une fonction Python.*
```python
if generate_all or args.file == "create_test":
    create_table('test')
    write_sql_file("create_dag", "create_test", query, to_log=True)

# dans le fichier dsn_processing/core/sql/utils.py 
def create_table(name):
    return  f"""CREATE TABLE {name} (id INTEGER PRIMARY KEY, field TEXT);"""
```

Une fois les modifications du fichier `dsn_processing/core/sql/generate_sql.py` effectu√©es, il faut re-g√©n√©rer l'ensemble des scripts impact√©s ou tout re-g√©n√©rer.

### Standards SQL - linter

#### Int√©r√™t d'un linter

On utilise un linter SQL pour assurer la lisibilit√© et l'homog√©n√©it√© des scripts. Cela permet aussi de d√©tecter en amont les erreurs les plus √©videntes. *Pour plus d'informations sur les linter en g√©n√©ral, voir ce [lien](https://en.wikipedia.org/wiki/Lint_(software)).*

On utilise le linter [sqlfluff](https://github.com/sqlfluff/sqlfluff). Il peut √™tre install√© avec pip. Un fichier de configurations `.sqlfluff` est pr√©sent √† la racine du dossier, il d√©finit les particularit√©s du linter pour le projet Champollion.

#### Comment *linter* un fichier <name>.sql ?

1. S'assurer que sqlfluff est bien install√© avec `sqlfluff -h`.
2. Lancez la ligne de commande suivante :
```bash
sqlfluff lint <name>.sql
```
3. Si des erreurs s'affichent :
    * Soit le fichier est g√©n√©r√© par Python et on corrige les erreurs dans le fichier Python directement. Puis on reg√©n√®re le fichier SQL.
    * Soit le fichier SQL n'est pas g√©n√©r√© par un autre fichier et on corrige directement le fichier SQL.
4. On relance et on corrige les erreurs tant que :
```bash
sqlfluff lint <name>.sql
```
n'affiche pas
```bash
All Finished üìú üéâ! 
```

Si on souhaite faire passer les tests √† l'ensemble des scripts SQL, on √©x√©cutera : 
```bash
sqlfluff lint core/sql/*/*.sql
```